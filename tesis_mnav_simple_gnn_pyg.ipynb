{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vp0qGc5z4AOk"
   },
   "source": [
    "# MNAV - Simple GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDifkXbM4UUX"
   },
   "source": [
    "Dataset: MNAV\n",
    "\n",
    "Modelo: GNN simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4qV8TIQYl62",
    "tags": []
   },
   "source": [
    "## Importar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 27989,
     "status": "ok",
     "timestamp": 1635510361213,
     "user": {
      "displayName": "Facundo Lezama",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjvX7z6H8HKQ9Q4HSRF20NaPjvwtJ3pQh0TGed2XQ=s64",
      "userId": "08104556030349101598"
     },
     "user_tz": 180
    },
    "id": "OjHf3j75Agti"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fede/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from itertools import combinations\n",
    "from copy import deepcopy\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import torch\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn.conv.dna_conv import Linear\n",
    "from torch_geometric.utils import to_networkx, is_undirected, to_undirected\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ChebConv, SAGEConv, TAGConv, GraphConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMFznhF9wDxB"
   },
   "source": [
    "El dataset se encuentra disponible en https://github.com/ffedee7/posifi_mnav/tree/master/data_analysis. El dataset disponible está anonimizado pero se puede deshacer con el código de ese repositorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1270,
     "status": "ok",
     "timestamp": 1635454213295,
     "user": {
      "displayName": "Facundo Lezama",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjvX7z6H8HKQ9Q4HSRF20NaPjvwtJ3pQh0TGed2XQ=s64",
      "userId": "08104556030349101598"
     },
     "user_tz": 180
    },
    "id": "jXw5-YfeAgtp"
   },
   "outputs": [],
   "source": [
    "dataset = 'datos2.csv'\n",
    "df = pd.read_csv(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "executionInfo": {
     "elapsed": 1105,
     "status": "ok",
     "timestamp": 1635454214395,
     "user": {
      "displayName": "Facundo Lezama",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjvX7z6H8HKQ9Q4HSRF20NaPjvwtJ3pQh0TGed2XQ=s64",
      "userId": "08104556030349101598"
     },
     "user_tz": 180
    },
    "id": "OIhn7QSoAgtq",
    "outputId": "37bf3f47-b29c-4af5-aec4-a23a675b0eef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10469, 189)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wifi-c0:7b:bc:36:af:80</th>\n",
       "      <th>wifi-1c:1d:86:b8:ac:80</th>\n",
       "      <th>wifi-f8:4f:57:ab:ce:20</th>\n",
       "      <th>wifi-dc:a5:f4:43:72:e0</th>\n",
       "      <th>wifi-c0:7b:bc:36:af:40</th>\n",
       "      <th>wifi-c0:7b:bc:36:9e:10</th>\n",
       "      <th>wifi-1c:1d:86:d0:ef:00</th>\n",
       "      <th>wifi-dc:a5:f4:43:79:20</th>\n",
       "      <th>wifi-ec:08:6b:ec:36:12</th>\n",
       "      <th>wifi-1c:1d:86:9f:99:20</th>\n",
       "      <th>...</th>\n",
       "      <th>wifi-84:74:2a:01:41:27</th>\n",
       "      <th>wifi-90:f6:52:f8:d1:dc</th>\n",
       "      <th>wifi-6a:fb:7e:26:34:bc</th>\n",
       "      <th>wifi-34:fa:40:08:f1:c8</th>\n",
       "      <th>wifi-54:22:f8:90:0b:b6</th>\n",
       "      <th>wifi-b0:4e:26:78:8d:e2</th>\n",
       "      <th>wifi-d4:6e:0e:3a:9f:fa</th>\n",
       "      <th>wifi-58:6d:8f:d7:68:d6</th>\n",
       "      <th>wifi-ac:84:c6:56:17:0e</th>\n",
       "      <th>wifi-00:87:01:6f:b6:ae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8278.000000</td>\n",
       "      <td>8313.000000</td>\n",
       "      <td>4127.000000</td>\n",
       "      <td>9365.000000</td>\n",
       "      <td>10289.000000</td>\n",
       "      <td>9230.000000</td>\n",
       "      <td>2001.000000</td>\n",
       "      <td>9381.000000</td>\n",
       "      <td>4711.000000</td>\n",
       "      <td>10024.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-83.642426</td>\n",
       "      <td>-74.133406</td>\n",
       "      <td>-81.040950</td>\n",
       "      <td>-77.477950</td>\n",
       "      <td>-75.078725</td>\n",
       "      <td>-82.051896</td>\n",
       "      <td>-84.896052</td>\n",
       "      <td>-74.916214</td>\n",
       "      <td>-77.211208</td>\n",
       "      <td>-78.225359</td>\n",
       "      <td>...</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>-88.0</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.342463</td>\n",
       "      <td>11.268483</td>\n",
       "      <td>11.139033</td>\n",
       "      <td>9.777461</td>\n",
       "      <td>8.545359</td>\n",
       "      <td>8.589948</td>\n",
       "      <td>10.273665</td>\n",
       "      <td>9.073052</td>\n",
       "      <td>12.254007</td>\n",
       "      <td>8.259183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-96.000000</td>\n",
       "      <td>-96.000000</td>\n",
       "      <td>-96.000000</td>\n",
       "      <td>-98.000000</td>\n",
       "      <td>-95.000000</td>\n",
       "      <td>-96.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-94.000000</td>\n",
       "      <td>-96.000000</td>\n",
       "      <td>-95.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>-88.0</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-89.000000</td>\n",
       "      <td>-83.000000</td>\n",
       "      <td>-91.000000</td>\n",
       "      <td>-85.000000</td>\n",
       "      <td>-81.000000</td>\n",
       "      <td>-89.000000</td>\n",
       "      <td>-94.000000</td>\n",
       "      <td>-81.000000</td>\n",
       "      <td>-88.000000</td>\n",
       "      <td>-85.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>-88.0</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-84.000000</td>\n",
       "      <td>-75.000000</td>\n",
       "      <td>-84.000000</td>\n",
       "      <td>-78.000000</td>\n",
       "      <td>-75.000000</td>\n",
       "      <td>-83.000000</td>\n",
       "      <td>-88.000000</td>\n",
       "      <td>-76.000000</td>\n",
       "      <td>-81.000000</td>\n",
       "      <td>-78.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>-88.0</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-79.000000</td>\n",
       "      <td>-66.000000</td>\n",
       "      <td>-72.000000</td>\n",
       "      <td>-71.000000</td>\n",
       "      <td>-69.000000</td>\n",
       "      <td>-77.000000</td>\n",
       "      <td>-79.000000</td>\n",
       "      <td>-70.000000</td>\n",
       "      <td>-67.000000</td>\n",
       "      <td>-73.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>-88.0</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-57.000000</td>\n",
       "      <td>-42.000000</td>\n",
       "      <td>-49.000000</td>\n",
       "      <td>-42.000000</td>\n",
       "      <td>-44.000000</td>\n",
       "      <td>-41.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-38.000000</td>\n",
       "      <td>-45.000000</td>\n",
       "      <td>-42.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>-88.0</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-89.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       wifi-c0:7b:bc:36:af:80  wifi-1c:1d:86:b8:ac:80  wifi-f8:4f:57:ab:ce:20  \\\n",
       "count             8278.000000             8313.000000             4127.000000   \n",
       "mean               -83.642426              -74.133406              -81.040950   \n",
       "std                  6.342463               11.268483               11.139033   \n",
       "min                -96.000000              -96.000000              -96.000000   \n",
       "25%                -89.000000              -83.000000              -91.000000   \n",
       "50%                -84.000000              -75.000000              -84.000000   \n",
       "75%                -79.000000              -66.000000              -72.000000   \n",
       "max                -57.000000              -42.000000              -49.000000   \n",
       "\n",
       "       wifi-dc:a5:f4:43:72:e0  wifi-c0:7b:bc:36:af:40  wifi-c0:7b:bc:36:9e:10  \\\n",
       "count             9365.000000            10289.000000             9230.000000   \n",
       "mean               -77.477950              -75.078725              -82.051896   \n",
       "std                  9.777461                8.545359                8.589948   \n",
       "min                -98.000000              -95.000000              -96.000000   \n",
       "25%                -85.000000              -81.000000              -89.000000   \n",
       "50%                -78.000000              -75.000000              -83.000000   \n",
       "75%                -71.000000              -69.000000              -77.000000   \n",
       "max                -42.000000              -44.000000              -41.000000   \n",
       "\n",
       "       wifi-1c:1d:86:d0:ef:00  wifi-dc:a5:f4:43:79:20  wifi-ec:08:6b:ec:36:12  \\\n",
       "count             2001.000000             9381.000000             4711.000000   \n",
       "mean               -84.896052              -74.916214              -77.211208   \n",
       "std                 10.273665                9.073052               12.254007   \n",
       "min                -99.000000              -94.000000              -96.000000   \n",
       "25%                -94.000000              -81.000000              -88.000000   \n",
       "50%                -88.000000              -76.000000              -81.000000   \n",
       "75%                -79.000000              -70.000000              -67.000000   \n",
       "max                -50.000000              -38.000000              -45.000000   \n",
       "\n",
       "       wifi-1c:1d:86:9f:99:20  ...  wifi-84:74:2a:01:41:27  \\\n",
       "count            10024.000000  ...                     7.0   \n",
       "mean               -78.225359  ...                   -97.0   \n",
       "std                  8.259183  ...                     0.0   \n",
       "min                -95.000000  ...                   -97.0   \n",
       "25%                -85.000000  ...                   -97.0   \n",
       "50%                -78.000000  ...                   -97.0   \n",
       "75%                -73.000000  ...                   -97.0   \n",
       "max                -42.000000  ...                   -97.0   \n",
       "\n",
       "       wifi-90:f6:52:f8:d1:dc  wifi-6a:fb:7e:26:34:bc  wifi-34:fa:40:08:f1:c8  \\\n",
       "count                     7.0                     7.0                     7.0   \n",
       "mean                    -95.0                   -90.0                   -84.0   \n",
       "std                       0.0                     0.0                     0.0   \n",
       "min                     -95.0                   -90.0                   -84.0   \n",
       "25%                     -95.0                   -90.0                   -84.0   \n",
       "50%                     -95.0                   -90.0                   -84.0   \n",
       "75%                     -95.0                   -90.0                   -84.0   \n",
       "max                     -95.0                   -90.0                   -84.0   \n",
       "\n",
       "       wifi-54:22:f8:90:0b:b6  wifi-b0:4e:26:78:8d:e2  wifi-d4:6e:0e:3a:9f:fa  \\\n",
       "count                     7.0                     7.0                     7.0   \n",
       "mean                    -89.0                   -88.0                   -93.0   \n",
       "std                       0.0                     0.0                     0.0   \n",
       "min                     -89.0                   -88.0                   -93.0   \n",
       "25%                     -89.0                   -88.0                   -93.0   \n",
       "50%                     -89.0                   -88.0                   -93.0   \n",
       "75%                     -89.0                   -88.0                   -93.0   \n",
       "max                     -89.0                   -88.0                   -93.0   \n",
       "\n",
       "       wifi-58:6d:8f:d7:68:d6  wifi-ac:84:c6:56:17:0e  wifi-00:87:01:6f:b6:ae  \n",
       "count                     7.0                     7.0                     7.0  \n",
       "mean                    -90.0                   -90.0                   -89.0  \n",
       "std                       0.0                     0.0                     0.0  \n",
       "min                     -90.0                   -90.0                   -89.0  \n",
       "25%                     -90.0                   -90.0                   -89.0  \n",
       "50%                     -90.0                   -90.0                   -89.0  \n",
       "75%                     -90.0                   -90.0                   -89.0  \n",
       "max                     -90.0                   -90.0                   -89.0  \n",
       "\n",
       "[8 rows x 188 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1635454214396,
     "user": {
      "displayName": "Facundo Lezama",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjvX7z6H8HKQ9Q4HSRF20NaPjvwtJ3pQh0TGed2XQ=s64",
      "userId": "08104556030349101598"
     },
     "user_tz": 180
    },
    "id": "hDAHd9mXpwec",
    "outputId": "dbf5f05a-eb40-47e6-c075-1e7fd39f104f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>wifi-c0:7b:bc:36:af:80</th>\n",
       "      <th>wifi-1c:1d:86:b8:ac:80</th>\n",
       "      <th>wifi-f8:4f:57:ab:ce:20</th>\n",
       "      <th>wifi-dc:a5:f4:43:72:e0</th>\n",
       "      <th>wifi-c0:7b:bc:36:af:40</th>\n",
       "      <th>wifi-c0:7b:bc:36:9e:10</th>\n",
       "      <th>wifi-1c:1d:86:d0:ef:00</th>\n",
       "      <th>wifi-dc:a5:f4:43:79:20</th>\n",
       "      <th>wifi-ec:08:6b:ec:36:12</th>\n",
       "      <th>...</th>\n",
       "      <th>wifi-84:74:2a:01:41:27</th>\n",
       "      <th>wifi-90:f6:52:f8:d1:dc</th>\n",
       "      <th>wifi-6a:fb:7e:26:34:bc</th>\n",
       "      <th>wifi-34:fa:40:08:f1:c8</th>\n",
       "      <th>wifi-54:22:f8:90:0b:b6</th>\n",
       "      <th>wifi-b0:4e:26:78:8d:e2</th>\n",
       "      <th>wifi-d4:6e:0e:3a:9f:fa</th>\n",
       "      <th>wifi-58:6d:8f:d7:68:d6</th>\n",
       "      <th>wifi-ac:84:c6:56:17:0e</th>\n",
       "      <th>wifi-00:87:01:6f:b6:ae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>location_7</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-92.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>-92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>location_3</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>location_8</td>\n",
       "      <td>-91.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>location_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.0</td>\n",
       "      <td>-85.0</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>location_3</td>\n",
       "      <td>-85.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 189 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      location  wifi-c0:7b:bc:36:af:80  wifi-1c:1d:86:b8:ac:80  \\\n",
       "0   location_7                   -84.0                   -71.0   \n",
       "1   location_3                   -84.0                   -72.0   \n",
       "2   location_8                   -91.0                   -82.0   \n",
       "3  location_10                     NaN                   -95.0   \n",
       "4   location_3                   -85.0                   -66.0   \n",
       "\n",
       "   wifi-f8:4f:57:ab:ce:20  wifi-dc:a5:f4:43:72:e0  wifi-c0:7b:bc:36:af:40  \\\n",
       "0                   -92.0                   -68.0                   -77.0   \n",
       "1                     NaN                   -75.0                   -79.0   \n",
       "2                     NaN                   -78.0                   -80.0   \n",
       "3                     NaN                   -91.0                   -85.0   \n",
       "4                     NaN                   -80.0                   -79.0   \n",
       "\n",
       "   wifi-c0:7b:bc:36:9e:10  wifi-1c:1d:86:d0:ef:00  wifi-dc:a5:f4:43:79:20  \\\n",
       "0                   -79.0                   -90.0                   -74.0   \n",
       "1                   -85.0                     NaN                   -87.0   \n",
       "2                   -93.0                     NaN                   -79.0   \n",
       "3                   -93.0                     NaN                   -89.0   \n",
       "4                   -86.0                     NaN                   -88.0   \n",
       "\n",
       "   wifi-ec:08:6b:ec:36:12  ...  wifi-84:74:2a:01:41:27  \\\n",
       "0                   -92.0  ...                     NaN   \n",
       "1                     NaN  ...                     NaN   \n",
       "2                     NaN  ...                     NaN   \n",
       "3                     NaN  ...                     NaN   \n",
       "4                     NaN  ...                     NaN   \n",
       "\n",
       "   wifi-90:f6:52:f8:d1:dc  wifi-6a:fb:7e:26:34:bc  wifi-34:fa:40:08:f1:c8  \\\n",
       "0                     NaN                     NaN                     NaN   \n",
       "1                     NaN                     NaN                     NaN   \n",
       "2                     NaN                     NaN                     NaN   \n",
       "3                     NaN                     NaN                     NaN   \n",
       "4                     NaN                     NaN                     NaN   \n",
       "\n",
       "   wifi-54:22:f8:90:0b:b6  wifi-b0:4e:26:78:8d:e2  wifi-d4:6e:0e:3a:9f:fa  \\\n",
       "0                     NaN                     NaN                     NaN   \n",
       "1                     NaN                     NaN                     NaN   \n",
       "2                     NaN                     NaN                     NaN   \n",
       "3                     NaN                     NaN                     NaN   \n",
       "4                     NaN                     NaN                     NaN   \n",
       "\n",
       "   wifi-58:6d:8f:d7:68:d6  wifi-ac:84:c6:56:17:0e  wifi-00:87:01:6f:b6:ae  \n",
       "0                     NaN                     NaN                     NaN  \n",
       "1                     NaN                     NaN                     NaN  \n",
       "2                     NaN                     NaN                     NaN  \n",
       "3                     NaN                     NaN                     NaN  \n",
       "4                     NaN                     NaN                     NaN  \n",
       "\n",
       "[5 rows x 189 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfqVFAK32Th4",
    "tags": []
   },
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CL6O8p3ZERrS"
   },
   "source": [
    "Se definen los APs que se quieren usar tanto para la construcción del grafo como para el modelo.\n",
    "\n",
    "En este caso usamos solamente los APs que se encuentran dentro del MNAV, es decir que descartamos los APs que aparecen en las medidas pero que no son los que se instalaron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1635454214396,
     "user": {
      "displayName": "Facundo Lezama",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjvX7z6H8HKQ9Q4HSRF20NaPjvwtJ3pQh0TGed2XQ=s64",
      "userId": "08104556030349101598"
     },
     "user_tz": 180
    },
    "id": "ynWQ8U8z50to"
   },
   "outputs": [],
   "source": [
    "APs_MAC_2_4 = ['wifi-dc:a5:f4:43:85:c0',\n",
    "'wifi-dc:a5:f4:43:27:e0',\n",
    "'wifi-f8:4f:57:ab:da:00',\n",
    "'wifi-5c:a4:8a:4c:05:c0',\n",
    "'wifi-1c:1d:86:ce:ef:b0',\n",
    "'wifi-dc:a5:f4:43:79:20',\n",
    "'wifi-c0:7b:bc:36:9e:10',\n",
    "'wifi-1c:1d:86:9f:99:20',\n",
    "'wifi-c0:7b:bc:36:af:40',\n",
    "'wifi-c0:7b:bc:36:af:80',\n",
    "'wifi-1c:1d:86:b6:ac:80',\n",
    "'wifi-dc:a5:f4:43:72:e0',\n",
    "'wifi-f8:4f:57:ab:d8:60',\n",
    "'wifi-dc:a5:f4:43:72:90',\n",
    "'wifi-f8:4f:57:ab:ce:20']\n",
    "\n",
    "APs_MAC_5 = ['wifi-dc:a5:f4:45:85:b0',\n",
    "'wifi-dc:a5:f4:45:27:e0',\n",
    "'wifi-f8:4f:57:ad:d9:60',\n",
    "'wifi-5c:a4:8a:4e:05:30',\n",
    "'wifi-1c:1d:86:d0:ef:00',\n",
    "'wifi-dc:a5:f4:45:79:10',\n",
    "'wifi-c0:7b:bc:38:9e:00',\n",
    "'wifi-1c:1d:86:a1:99:00',\n",
    "'wifi-c0:7b:bc:38:af:30',\n",
    "'wifi-c0:7b:bc:38:af:70',\n",
    "'wifi-1c:1d:86:b8:ac:80',\n",
    "'wifi-dc:a5:f4:45:72:d0',\n",
    "'wifi-f8:4f:57:ad:d7:c0',\n",
    "'wifi-dc:a5:f4:45:72:80',\n",
    "'wifi-f8:4f:57:ad:cd:80']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1635454214397,
     "user": {
      "displayName": "Facundo Lezama",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjvX7z6H8HKQ9Q4HSRF20NaPjvwtJ3pQh0TGed2XQ=s64",
      "userId": "08104556030349101598"
     },
     "user_tz": 180
    },
    "id": "q0BCpSLFAgts"
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset_path, dataset_percentage=None):\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    # paso los NaN a 0\n",
    "    df = df.fillna(0) \n",
    "\n",
    "    # sumo 100 a los valores de RSSI y ahora 0 es el minimo\n",
    "    df.iloc[:,1:] = 100 + df.iloc[:,1:]\n",
    "    values = df.iloc[:,1:]\n",
    "\n",
    "    # las medidas originales en 0 las asumo como que estaban muy lejos\n",
    "    # entonces las dejo en 0 que es el nuevo valor minimo\n",
    "    values[values==100] = 0 \n",
    "    df.iloc[:,1:] = values\n",
    "\n",
    "    # armo dos datsets: uno con las medidas solamente de la frecuencia\n",
    "    # 2.4GHz y otro con las frecuencias 2.4GHz y 5GHz\n",
    "    data_2_4 = df[['location'] + APs_MAC_2_4] # REVISAR PORQUE CREO QUE NO LO VUELVO A USAR\n",
    "    data_2_4_5 = df[['location'] + APs_MAC_2_4 + APs_MAC_5]\n",
    "\n",
    "    if dataset_percentage:\n",
    "        data_2_4_5 = data_2_4_5.sample(frac=dataset_percentage)     \n",
    "    \n",
    "    # paso las zonas por un ordinal encoder\n",
    "    enc = OrdinalEncoder(dtype=int)\n",
    "    y = enc.fit_transform(data_2_4_5['location'].values.reshape(-1,1))\n",
    "    X = data_2_4_5.iloc[:,1:].values\n",
    "\n",
    "    # print(enc.categories_)\n",
    "\n",
    "    # separo el dataset en train y test 80-20\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "    print(\"X_train shape: \", X_train.shape)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmC2Dsazdx7i",
    "tags": []
   },
   "source": [
    "## Grafo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cF2ZViCq3a_Q"
   },
   "source": [
    "En las siguientes celdas se describe un poco el dataset y se muestran las distribuciones de potencia por AP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1635454218455,
     "user": {
      "displayName": "Facundo Lezama",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjvX7z6H8HKQ9Q4HSRF20NaPjvwtJ3pQh0TGed2XQ=s64",
      "userId": "08104556030349101598"
     },
     "user_tz": 180
    },
    "id": "xHfjTzU5E2eq"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def graph_creator(X_G, th=10, cols=None):\n",
    "    \"\"\"\n",
    "    Dado un dataset y un threshold se arma un grafo basado en las medidas de RRSI\n",
    "    \"\"\"\n",
    "\n",
    "    columns = cols if cols else ['AP1', 'AP2', 'AP3', 'AP4', 'AP5', 'AP6', 'AP7', 'AP8', 'AP9', 'AP10', 'AP11', 'AP12', 'AP13', 'AP14', 'AP15']\n",
    "    df_data_train = pd.DataFrame(X_G, columns=columns)\n",
    "    df_G = pd.DataFrame(columns = ['from', 'to', 'weight']) \n",
    "\n",
    "    for ap in columns:\n",
    "        # para cada AP me quedo con las instancias donde el RSSI esta en el rango\n",
    "        # (max-th) intentando estimar las instancias mas cercanas al AP\n",
    "        max_val = df_data_train[ap].max()\n",
    "        df_aux_i = df_data_train[df_data_train[ap]  > (max_val - th)]\n",
    "        df_aux_i = df_aux_i.drop(ap, axis=1) \n",
    "        df_aux_i.head()\n",
    "\n",
    "        for k, v in df_aux_i.mean().items():\n",
    "            # armo las aristas con el promedio de RSSI que ven las instancias \n",
    "            # filtradas al resto de los APs\n",
    "            # weight = v\n",
    "            # if df_G.loc[(df_G['from'] == k) & (df_G['to'] == ap)].weight.any():\n",
    "            #     weight = np.mean([float(df_G.loc[(df_G['from'] == k) & (df_G['to'] == ap)].weight), weight])\n",
    "            #     df_G.loc[(df_G['from'] == k) & (df_G['to'] == ap)] = k, ap, weight\n",
    "            df_G = df_G.append({'from':ap, 'to': k, 'weight': v}, ignore_index=True)\n",
    "        \n",
    "\n",
    "    edge_index_first_row = []\n",
    "    edge_index_second_row = []\n",
    "    edge_attr = []\n",
    "    for index, row in df_G.iterrows():\n",
    "        edge_index_first_row.append(columns.index(row['from']))\n",
    "        edge_index_second_row.append(columns.index(row['to']))\n",
    "        edge_attr.append([float(row.weight)])\n",
    "\n",
    "    \n",
    "    edge_index = torch.tensor([edge_index_first_row, edge_index_second_row], dtype=torch.long)\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)                           \n",
    "    edge_index, edge_attr = to_undirected(edge_index, edge_attr, reduce=\"mean\")\n",
    "    return edge_index, edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def build_dataset(X, y, graph):\n",
    "    dataset = []\n",
    "    for i in range(len(y)):\n",
    "        data = deepcopy(graph)\n",
    "        data.x = torch.Tensor(X[i])\n",
    "        data.y = torch.Tensor(y[i])\n",
    "        data.train_mask = torch.Tensor([True]*len(y))\n",
    "        data.val_mask = torch.Tensor([True]*len(y))\n",
    "        data.test_mask = torch.Tensor([True]*len(y))                \n",
    "        dataset.append(data)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "class GNN_GCNConv(torch.nn.Module):\n",
    "    def __init__(self, conv_out_features: list = [16, 20]):\n",
    "        super().__init__()\n",
    "        self.conv_out_features = conv_out_features\n",
    "        self.conv1 = GCNConv(2, self.conv_out_features[0], bias=True, normalize=True)\n",
    "        self.conv2 = GCNConv(self.conv_out_features[0], self.conv_out_features[1], bias=True, normalize=True)\n",
    "        self.fc = torch.nn.Linear(self.conv_out_features[-1]*15,16)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        # print(\"After Conv1: \", x.shape)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)        \n",
    "        # print(\"After Conv2: \", x.shape)\n",
    "\n",
    "        # x = torch.flatten(x, 0)\n",
    "        x = torch.reshape(x, (int(x.shape[0]/15),self.conv_out_features[-1]*15))\n",
    "        # print(\"After Flatten: \", x.shape)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        x = F.relu(x)        \n",
    "        # print(\"After FC: \", x.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "class GNN_TAGConv(torch.nn.Module):\n",
    "    def __init__(self, k: list = [1,1], conv_out_features: list = [16, 20]):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.conv_out_features = conv_out_features\n",
    "        self.conv1 = TAGConv(2, self.conv_out_features[0], K=self.k[0], bias=True, normalize=True)\n",
    "        self.conv2 = TAGConv(self.conv_out_features[0], self.conv_out_features[1], K=self.k[1], bias=True, normalize=True)\n",
    "        self.fc = torch.nn.Linear(self.conv_out_features[-1]*15,16)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        # print(\"After Conv1: \", x.shape)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)        \n",
    "        # print(\"After Conv2: \", x.shape)\n",
    "\n",
    "        # x = torch.flatten(x, 0)\n",
    "        x = torch.reshape(x, (int(x.shape[0]/15),self.conv_out_features[-1]*15))\n",
    "        # print(\"After Flatten: \", x.shape)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        x = F.relu(x)        \n",
    "        # print(\"After FC: \", x.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "class GNN_GraphConv(torch.nn.Module):\n",
    "    def __init__(self, aggr = \"add\", conv_out_features: list = [16, 20]):\n",
    "        super().__init__()\n",
    "        self.aggr = aggr\n",
    "        self.conv_out_features = conv_out_features\n",
    "        self.conv1 = GraphConv(2, self.conv_out_features[0], aggr=self.aggr, bias=True)\n",
    "        self.conv2 = GraphConv(self.conv_out_features[0], self.conv_out_features[1], aggr=self.aggr, bias=True)\n",
    "        self.fc = torch.nn.Linear(self.conv_out_features[-1]*15,16)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        # print(\"After Conv1: \", x.shape)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)        \n",
    "        # print(\"After Conv2: \", x.shape)\n",
    "\n",
    "        # x = torch.flatten(x, 0)\n",
    "        x = torch.reshape(x, (int(x.shape[0]/15),self.conv_out_features[-1]*15))\n",
    "        # print(\"After Flatten: \", x.shape)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        # x = F.relu(x)        \n",
    "        # print(\"After FC: \", x.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHsZyzkAZKlK",
    "tags": []
   },
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "plt.hist(data.edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# data.edge_attr = (data.edge_attr - data.edge_attr.mean()) / data.edge_attr.std()\n",
    "data.edge_attr = (data.edge_attr - data.edge_attr.min()) / data.edge_attr.max()\n",
    "data.edge_attr *= 4\n",
    "# data.edge_attr = torch.nn.functional.normalize(data.edge_attr, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "g = to_networkx(data, edge_attrs=[\"edge_attr\"], to_undirected=True)\n",
    "weights = nx.get_edge_attributes(g,'edge_attr').values()\n",
    "# pos = nx.circular_layout(g)\n",
    "graph = nx.draw(g, width=list(weights), with_labels=True, node_color='black', font_color=\"white\", font_family='Helvetica')\n",
    "plt.savefig(\"mnav_graph.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 356,
     "status": "ok",
     "timestamp": 1635462144424,
     "user": {
      "displayName": "Facundo Lezama",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjvX7z6H8HKQ9Q4HSRF20NaPjvwtJ3pQh0TGed2XQ=s64",
      "userId": "08104556030349101598"
     },
     "user_tz": 180
    },
    "id": "0MsSCtZkUDbj"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Split de los datos y armado del objeto Data con el grafo\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocess_dataset(dataset)\n",
    "edge_index, edge_attr = graph_creator(X_train[:,:15], th=10) #el grafo lo armo solo con los datos de 2.4Ghz\n",
    "data = Data(edge_index=edge_index, edge_attr=edge_attr, num_nodes=15)\n",
    "print(f\"Undirected: {data.is_undirected()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Armado del dataset\n",
    "\n",
    "x_training_data = np.reshape(X_train,(X_train.shape[0],15,2))\n",
    "x_test_data = np.reshape(X_test,(X_test.shape[0],15,2))\n",
    "y_training_data = y_train\n",
    "y_test_data = y_test\n",
    "\n",
    "#normalize (x-mean)/std\n",
    "mean = x_training_data.mean(axis=0)\n",
    "std = x_training_data.std(axis=0)\n",
    "\n",
    "x_training_data = x_training_data - mean\n",
    "x_training_data /= std\n",
    "x_test_data = x_test_data - mean\n",
    "x_test_data /= std\n",
    "\n",
    "train_dataset = build_dataset(x_training_data, y_training_data, data)\n",
    "test_dataset = build_dataset(x_test_data, y_test_data, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### GCNConv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model = GNN_GCNConv(conv_out_features=[20,20]).to(device)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "train_accuracy = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "\n",
    "m = torch.nn.Softmax(dim=1)\n",
    "\n",
    "for epoch in range(100):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    \n",
    "    # TRAIN\n",
    "    model.train()\n",
    "    train_accuracy_epoch = []\n",
    "    train_loss_epoch = []\n",
    "    for data in train_loader:\n",
    "        import ipdb; ipdb.set_trace()\n",
    "        optimizer.zero_grad()\n",
    "        # print(data.x.shape)\n",
    "        # print(data.y.shape)\n",
    "        \n",
    "        \n",
    "        out = model(data.to(device))\n",
    "        # print(out)\n",
    "        # out_softmax = np.array(torch.argmax(out, dim=0)).item()\n",
    "        # out_softmax = torch.tensor([out_softmax])\n",
    "        loss_result = loss(out, data.y.type(torch.long))        \n",
    "        loss_result.backward()\n",
    "        \n",
    "        train_loss_epoch.append(loss_result.detach().cpu())\n",
    "        output = m(out)\n",
    "        train_accuracy_epoch.append(accuracy_score(data.y.cpu().reshape(-1).type(torch.long), np.array(torch.argmax(output.cpu(), axis=1))))\n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    # if scheduler.get_last_lr()[0] > 0.0005:\n",
    "    #     scheduler.step()\n",
    "\n",
    "    train_accuracy.append(np.mean(train_accuracy_epoch))\n",
    "    train_loss.append(np.mean(train_loss_epoch))\n",
    "\n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "    test_accuracy_epoch = []\n",
    "    test_loss_epoch = []\n",
    "    for data in test_loader:\n",
    "        out = model(data.to(device))\n",
    "        loss_result = loss(out, data.y.type(torch.long))        \n",
    "        \n",
    "        test_loss_epoch.append(loss_result.detach().cpu())\n",
    "        output = m(out)\n",
    "        test_accuracy_epoch.append(accuracy_score(data.y.cpu().reshape(-1).type(torch.long), np.array(torch.argmax(output.cpu(), axis=1))))\n",
    "\n",
    "    test_accuracy.append(np.mean(test_accuracy_epoch))\n",
    "    test_loss.append(np.mean(test_loss_epoch))\n",
    "\n",
    "\n",
    "print(f\"Last LR: {scheduler.get_last_lr()}\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_loss, label=\"Train loss\")\n",
    "plt.plot(test_loss, label=\"Validation loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_accuracy, label=\"Train accuracy\")\n",
    "plt.plot(test_accuracy, label=\"Validation accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "m = torch.nn.Softmax(dim=1)\n",
    "output = m(out)\n",
    "accuracy = accuracy_score(data.y.cpu().reshape(-1).type(torch.long), np.array(torch.argmax(output.cpu(), axis=1)))\n",
    "\n",
    "print(accuracy)\n",
    "print(classification_report(data.y.cpu().reshape(-1).type(torch.long), np.array(torch.argmax(output.cpu(), axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### TAGConv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model = GNN_TAGConv(k=[2,2], conv_out_features=[20,20]).to(device)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "train_accuracy = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "best_test_accuracy = 0\n",
    "\n",
    "m = torch.nn.Softmax(dim=1)\n",
    "\n",
    "for epoch in range(50):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    \n",
    "    # TRAIN\n",
    "    model.train()\n",
    "    train_accuracy_epoch = []\n",
    "    train_loss_epoch = []\n",
    "    for data in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # print(data.x.shape)\n",
    "        # print(data.y.shape)\n",
    "        \n",
    "        \n",
    "        out = model(data.to(device))\n",
    "        # print(out)\n",
    "        # out_softmax = np.array(torch.argmax(out, dim=0)).item()\n",
    "        # out_softmax = torch.tensor([out_softmax])\n",
    "        loss_result = loss(out, data.y.type(torch.long))        \n",
    "        loss_result.backward()\n",
    "        \n",
    "        train_loss_epoch.append(loss_result.detach().cpu())\n",
    "        output = m(out)\n",
    "        train_accuracy_epoch.append(accuracy_score(data.y.cpu().reshape(-1).type(torch.long), np.array(torch.argmax(output.cpu(), axis=1))))\n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch+1)%10 == 0:\n",
    "        scheduler.step()\n",
    "\n",
    "    train_accuracy.append(np.mean(train_accuracy_epoch))\n",
    "    train_loss.append(np.mean(train_loss_epoch))\n",
    "\n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "    test_accuracy_epoch = []\n",
    "    test_loss_epoch = []\n",
    "    for data in test_loader:\n",
    "        out = model(data.to(device))\n",
    "        loss_result = loss(out, data.y.type(torch.long))        \n",
    "        \n",
    "        test_loss_epoch.append(loss_result.detach().cpu())\n",
    "        output = m(out)\n",
    "        test_accuracy_epoch.append(accuracy_score(data.y.cpu().reshape(-1).type(torch.long), np.array(torch.argmax(output.cpu(), axis=1))))\n",
    "\n",
    "    test_accuracy.append(np.mean(test_accuracy_epoch))\n",
    "    if test_accuracy[-1] > best_test_accuracy:\n",
    "        best_test_accuracy = test_accuracy[-1]        \n",
    "        torch.save(model.state_dict(), \"MNAV_best_model.pth\")\n",
    "        \n",
    "    test_loss.append(np.mean(test_loss_epoch))\n",
    "    print(f\"    Train Loss {np.mean(train_loss_epoch)}, Val Loss {np.mean(test_loss_epoch)}\")\n",
    "\n",
    "\n",
    "print(f\"Last LR: {scheduler.get_last_lr()}\")\n",
    "print(f\"Best Accuracy: Train {np.max(train_accuracy)}, Val {np.max(test_accuracy)}\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_loss, label=\"Train loss\")\n",
    "plt.plot(test_loss, label=\"Validation loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_accuracy, label=\"Train accuracy\")\n",
    "plt.plot(test_accuracy, label=\"Validation accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "m = torch.nn.Softmax(dim=1)\n",
    "output = m(out)\n",
    "accuracy = accuracy_score(data.y.cpu().reshape(-1).type(torch.long), np.array(torch.argmax(output.cpu(), axis=1)))\n",
    "\n",
    "print(accuracy)\n",
    "print(classification_report(data.y.cpu().reshape(-1).type(torch.long), np.array(torch.argmax(output.cpu(), axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GraphConv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model = GNN_GraphConv(aggr=\"mean\", conv_out_features=[20,20]).to(device)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "train_accuracy = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "\n",
    "m = torch.nn.Softmax(dim=1)\n",
    "\n",
    "for epoch in range(100):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    \n",
    "    # TRAIN\n",
    "    model.train()\n",
    "    train_accuracy_epoch = []\n",
    "    train_loss_epoch = []\n",
    "    for data in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # print(data.x.shape)\n",
    "        # print(data.y.shape)\n",
    "        \n",
    "        \n",
    "        out = model(data.to(device))\n",
    "        # print(out)\n",
    "        # out_softmax = np.array(torch.argmax(out, dim=0)).item()\n",
    "        # out_softmax = torch.tensor([out_softmax])\n",
    "        \n",
    "        import ipdb; ipdb.set_trace()\n",
    "        \n",
    "        loss_result = loss(out, data.y.type(torch.long))        \n",
    "        loss_result.backward()\n",
    "        \n",
    "        train_loss_epoch.append(loss_result.detach().cpu())\n",
    "        output = m(out)\n",
    "        train_accuracy_epoch.append(accuracy_score(data.y.cpu().reshape(-1).type(torch.long), np.array(torch.argmax(output.cpu(), axis=1))))\n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    # if scheduler.get_last_lr()[0] > 0.0005:\n",
    "    #     scheduler.step()\n",
    "\n",
    "    train_accuracy.append(np.mean(train_accuracy_epoch))\n",
    "    train_loss.append(np.mean(train_loss_epoch))\n",
    "\n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "    test_accuracy_epoch = []\n",
    "    test_loss_epoch = []\n",
    "    for data in test_loader:\n",
    "        out = model(data.to(device))\n",
    "        loss_result = loss(out, data.y.type(torch.long))        \n",
    "        \n",
    "        test_loss_epoch.append(loss_result.detach().cpu())\n",
    "        output = m(out)\n",
    "        test_accuracy_epoch.append(accuracy_score(data.y.cpu().reshape(-1).type(torch.long), np.array(torch.argmax(output.cpu(), axis=1))))\n",
    "\n",
    "    test_accuracy.append(np.mean(test_accuracy_epoch))\n",
    "    test_loss.append(np.mean(test_loss_epoch))\n",
    "\n",
    "\n",
    "print(f\"Last LR: {scheduler.get_last_lr()}\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_loss, label=\"Train loss\")\n",
    "plt.plot(test_loss, label=\"Validation loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_accuracy, label=\"Train accuracy\")\n",
    "plt.plot(test_accuracy, label=\"Validation accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "m = torch.nn.Softmax(dim=1)\n",
    "output = m(out)\n",
    "accuracy = accuracy_score(data.y.cpu().reshape(-1).type(torch.long), np.array(torch.argmax(output.cpu(), axis=1)))\n",
    "\n",
    "print(accuracy)\n",
    "print(classification_report(data.y.cpu().reshape(-1).type(torch.long), np.array(torch.argmax(output.cpu(), axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Análisis variando cantidad de muestras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda:1')\n",
    "batch_size = 16\n",
    "learning_rate = 0.01  \n",
    "print_every = 5\n",
    "\n",
    "porcentajes = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "accuracy = {\"0.1\":[], \"0.2\":[], \"0.3\":[], \"0.4\":[], \"0.5\":[], \"0.6\":[], \"0.7\":[], \"0.8\":[], \"0.9\":[], \"1\":[]}\n",
    "\n",
    "for porc in porcentajes:\n",
    "    print('Porcentaje de datos: ', porc)\n",
    "    \n",
    "    for i in range(10):    \n",
    "\n",
    "        X_train, X_test, y_train, y_test = preprocess_dataset(dataset, dataset_percentage=porc)\n",
    "\n",
    "        # x_training_data = np.reshape(X_train,(X_train.shape[0],15,2))\n",
    "        # x_test_data = np.reshape(X_test,(X_test.shape[0],15,2))\n",
    "        y_training_data = y_train\n",
    "        y_test_data = y_test\n",
    "\n",
    "        #normalize (x-mean)/std\n",
    "        mean = X_train.mean(axis=0)\n",
    "        std = X_train.std(axis=0)\n",
    "\n",
    "        x_training_data = X_train - mean\n",
    "        x_training_data /= std\n",
    "        x_test_data = X_test - mean\n",
    "        x_test_data /= std\n",
    "\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        from sklearn.metrics import accuracy_score, classification_report     \n",
    "        \n",
    "        neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "        neigh.fit(x_training_data, y_training_data)\n",
    "        y_pred_knn = neigh.predict(x_test_data)\n",
    "        acc = accuracy_score(y_test_data, y_pred_knn)\n",
    "\n",
    "        print(f\"Accuracy: {acc}\")\n",
    "        accuracy[str(porc)].append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "n4qV8TIQYl62",
    "gfqVFAK32Th4",
    "fmC2Dsazdx7i",
    "YHsZyzkAZKlK",
    "gU46OaNwNj7Z",
    "P3QFKooiTRQF",
    "DdJpdEQmWRuO",
    "9Y6Zs61LXiik",
    "MTSumaDohl3K",
    "d2MElifG5G5q",
    "2EjKrCuHim66",
    "iSVeCEtNim7C",
    "1uwrgRzJim7D",
    "kpCBGsGe6J3Z",
    "Tb5Kdlky-4DN",
    "2cJTvncIOZ6I",
    "SwovNzD_THq_",
    "V5fnHhVyXMC4"
   ],
   "name": "tesis_mnav_simple_gnn.ipynb",
   "provenance": [
    {
     "file_id": "1AOWB0JuB1YtTUv8waFAYjdVb27Oi_zVw",
     "timestamp": 1617051239005
    },
    {
     "file_id": "1-veytfLbAuWzFrDTNxXhvsEfn8Th0D2K",
     "timestamp": 1616972473551
    },
    {
     "file_id": "1iQI9YVQL7SxQAvy2A4VAE8jJCv7nBfbI",
     "timestamp": 1615845377065
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
